@doc.Processes
"Consider an incremental process model, abstractly of form `µP.[a→(P*b)]`. Which is to say, process `P` is described as a step function that takes a single input of type `a` and generates a single output of type `b`, along with an updated process `P` for the next step (thus modeling stateful behavior). Each step should terminate, but the process overall might allow an unbounded number of steps. (A process that terminates should return a value indicating so.)
 
 OOP-like objects can be modeled using dependent types: `a` contains method name, `b` is result whose type depends on `a`, `P` is the object. It is also feasible for types `a` and `b` to vary between steps, e.g. to model multi-step protocols, typestate, or evolving objects.
 
 Compared to conventional process-as-a-loop models, AO's model offers effective process control and composition without relying on side-effects or indeterminacy. Processes may trivially be halted between steps, or composed sequentially or in parallel (e.g. splitting a pair, combining results). Concurrent behaviors are readily expressed. A process can model environments and networks, routing messages or establishing channels between named child processes.  
 
 As shorthand for the type of a simple process, I'll use U+21A3: a ↣ b.
  
 It is feasible to use the abstract process model directly, leveraging fixpoints. However, a symbolic representation could enable many explicit optimizations, and eliminate some unnecessary intermediate structures. An ABC optimizer on the final block could do some of this, but reducing the burden on smart compilers is a good thing. So the actual representation for AO's processes is symbolic, abstracted by a sealer, with staged compilation to a block upon request. 
 
 NOTE: Processes encapsulate state, and thus diverge from source. Consequently, long-running processes aren't ideal for live programming or continuous deployment scenarios: we cannot reliably map an update on the source back into an update of the process. (Conversely, we cannot trivially trace an error in the process back to the source.) Reactive demand programming (RDP) is the preferred model for long-running behavior. The incremental process model is useful for folds, processing large data structures, and potentially for implementing RDP. 
~

@doc.ProcessRep
"A little on the concrete representation for incremental subprocesses.
 
 A point to consider is that an incremental process will presumably be executed many times by many subsequent inputs. Thus, it can be useful to treat inputs as streams rather than atoms. Relevantly, there is a useful distinction between a pair of streams vs. a stream of pairs:
 
     (a`Stream * b`Stream)    vs.    (a*b)`Stream
 
 Similarly, we can distinguish a sum of streams vs. a stream of sums.
 
     (a`Stream + b`Stream)    vs.    (a+b)`Stream
 
 However, in the sum case, the two aren't representationally equivalent. Consider a variation:
 
     ((1+a)`Stream * (1+b)`Stream) ~  (a+b)`Stream
 
 Essentially, we can use a pair of streams with gaps in them to model a single stream that has no gaps. Sadly, this means we can represent some invalid states locally, e.g. neither or both streams are active. We must rely on discipline or implementation-hiding encapsulation. OTOH, this design extends readily to larger sums, e.g. for a stream of ((a+b)+c), we don't need an `(1+(a+b))` intermediate. 
 
 So... what does it even mean for a process or subprocess to be inactive? 
 
 This gets pretty close to how RDP is implemented and optimized. We only need to extend this with the idea of duration coupling, a reasonable assumption that every process is a subprocess (part of a larger process), and logical asynchrony (i.e. that the `a` and `b` branches may have different logical delays).
 
 
 If there was no delay, i.e. very input resulted in all the available outputs, then 
 
 It would be convenient if we could simply ignore the inactive subprocesses. 
 
 It seems convenient to assume that we can just process updates for the steps with active inputs. But that doesn't work out if there is any sort of delay between steps. OTOH, we certainly want to stop processing an inactive process after some small number of steps, otherwise we'll never know how much we need to run the process to get all the outputs. So this might be achieved by tracking logical delays.
 
 (For the current abstract process model, our logical delays will be discrete steps. RDP is very similar, except shifts from streams to a more continuous signal concept with rational time.)
 
 
 
 Well, one useful assumption is that a process has always been inactive before it is first installed, and that it is also inactive for any number of steps after it is removed. 

With duration coupling, it means that every inactive input step must correspond to an inactive output step. But some delay (by a number of steps) might be permitted. So it may be necessary to still process the (1+a)`Stream to obtain outputs that occur in later steps. 

One possibility is that we simply ignore the inactivity, i.e. operate blind to the states where a subprogram is inactive. 
 
 
 
     
 
 
 we'll need a notion of gaps in a stream, and an additional (disciplined) constraint that the gaps are filled in other streams without any overlap:
 
 To generalize across subprograms, we must always assume that a product type is part of a sum. Consequently, this notion of gaps will be pervasive:

 we can assume that products are always part of a sum, so we'll always need this notion of gaps even if we don't use it.
 
 In the sums case, there is no direct equivalence: the righ. However, we could potentially 
 In addition, as this is an incremental process that will presumably be executed incrementally on multiple elements, it can be useful to think about type 'a' or `b` as a stream (a`S) of inputs. Relevantly, we can distinguish (a`S * b`S) from (a*b)`S at the symbolic optimizations layer, and only convert between them as necessary.
 
 To reduce the burden on the compiler, AO uses a symbolic model for processes and performs its own rewrite optimizations before compiling. The resulting block should then be easier to further optimize. The intention is that, in practice, processes should mostly be compiled via partial evaluation.
 
 Basic Processes (essentially an ADT based on Arrows):
 
     id    :: [a↣a]
     const :: c → [a↣(c*a)]
     fmap  :: [a→b] → [a↣b] (assume pure function; allow dead code elim)
     efmap :: [a→b] → [a↣b] (assume impure function; no dead code elim)
     state :: (∃s.([(a*s)↣(b*s)]*s)) → [a↣b]
     proc  :: (µP.[a→(P*b)]) → [a↣b]
 
     seq   :: ([a↣b]*[b↣c]) → [a↣c]
     par   :: ([a↣a']*[b↣b']) → [(a*b)↣(a'*b')]
     sum   :: ([a↣a']*[b↣b']) → [(a+b)↣(a'+b')]
 
 But this is just a start. I also expect to optimize for data shuffling primitives, and I might also want some extensible compilation model (such that new symbols and optimizations can be introduced, e.g. to optimize any stream-processing or list-processing). In some broad sense, this process model may reflect most of ABC and AO.
 
 The implementation of this symbolic model is trivial (label*value) pairs, where labels are generally text like "id" or "fmap", and the values are the arguments to the associated process. Rewrite rules mostly operate on sequences. Most complexity is shifted to the compiler, which must be aware of the symbols.
 
 The concrete implementation of processes is kept weakly abstract by a sealer and smart constructors.
~

@doc.TODO.p
"TODO: make it easy to develop rewrite rules and compilers of this form. 
 
 AO is awful for direct expression of pattern-matching and transform logics (seeing as there is no syntactic support for pattern matching), but should be okay after a layer or two abstractions and indirections, or possibly using a DSL. Mostly, I need rewrite rules on a sequence, or a grammar model for sequence-to-sequence (or stream-to-stream, or set-of-streams to set-of-streams as a weighted optimization problem). Tree-based is much less essential.
 
 TODO: make it easy to recognize pattern pairs for composition
~

@doc.suffix.p doc.Processes

@sealer.p [%{:p}]
@unsealer.p [%{.p}]
@seal.p sealer.p .apply
@unseal.p unsealer.p .apply
@unseal2.p swap unseal.p swap unseal.p


@doc.suffix.abstract.p "naive implementation of abstract process model"
@doc.lift.abstract.p "[a→b] -- µP.[a→(P*b)]"
@lift.abstract.p .bsecond .fixfirst
@doc.step.abstract.p "a [a↣b] -- b [a'↣b']; run process one step"
@step.abstract.p .apply x
@inc.abstract.p [%v 1 %r+c] lift.abstract.p
@test.inc.abstract.p 
  11 inc.abstract.p 
  [step.abstract.p] 16 repeat
  swap 27 assertEQ
