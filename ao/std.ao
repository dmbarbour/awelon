 abc plumbing conditionals blocks
 hands stdenv 
 lists loops streams process
 data_map
 bits
 math stats random

@doc.import.std "viable starting point for AO dictionaries"


@doc.NamingConventions
"AO makes heavy use of naming conventions. Common prefixes suggest automatic processing or type information. For example, 'doc.' indicates documentation for a word, and 'test.' indicates automatic testing in a mockup environment, and 'id.' indicates that a given expression should be equivalent to identity for all the types it accepts. Conversely, suffixes connote context. A suffix might identify a specific framework, project, spreadsheet, or programmer.
 
 Multi-part words unfortunately make plain-text AO verbose, noisy, and difficult to read. 
 
 The intention is to mitigate this issue at the editor. A set of rules (configurable per user, view, or project) shall translate common prefixes and suffixes into rendering with colors and styles and possible icons. For example, `foo.x` and `foo.y` might render the same text (just `foo`) but with different colors for the `x` vs. `y` context. Similarly, fuzzy autocomplete mechanisms in the editor can eliminate need to fully write out large words. `foo.x` might be found by typing just `fx`.
~

@doc.prefix.doc.
"AO does not have 'comments' in the usual sense. Instead, a word that starts with `doc.` can document some aspect of a dictionary - e.g. a word, project, or convention. This makes documentation a first-class, computable value, though most of the time it will simply be some text.
 
 In some cases, developers will be tempted to inject remarks directly into a word. This is doable (just `"this is a comment" drop` would do) but discouraged. Instead, consider refactoring the definition into words that can be documented independently, or that have self-explanatory names.
 
 At the moment, documentation lacks a clear convention or format, just a pseudo-markdown. Most likely, this will be addressed when we start processing documentation into HTML pages or similar.
~

@doc.prefix.test.
"Automated testing is an effective means to maintain software quality, avoid regressions, and achieve confidence in code. Test driven design can keep designs well grounded and incremental.  
 
 In AO, automatic testing is expressed simply by using the prefix 'test.' in the definitions of words. Test words can be systematically executed in a standard environment with a confined powerblock. A test can fail due to type errors, assertion failures, taking too much time or space, or emitting an error message effectfully through the powerblock.
 
 Testing has limits. You cannot prove, through testing, that bugs are absent. AO developers are encouraged also to leverage symbolic analysis, which is also expressed in a relatively dynamic manner in AO (e.g. use of the 'eqv.' or 'id.' prefixes).
~
@doc.warn.test "warnMsg --; (io) emit message"
@doc.error.test "errMsg --; (io) emit message then fail"
@warn.test "warn" p cmd.test drop
@error.test "error" p cmd.test drop
@doc.cmd.test "msg -- result; (io) call powerblock in standard location"
@cmd.test %zwl .apply x %rwz

@doc.prefix.eqv.
"There are many cases where two different expressions should be equivalent. Explicitly asserting so is useful! Not only may equivalencies serve as documentation, but they also can support automatic tests, and provide hints or tests for optimizers and refactoring tools. So prefix 'eqv' provides a generic way to suggest that two subprograms should be equivalent.
 
 The type of any 'eqv.foo' word should be:  ( -- [a→b] [a→b]). 
 
 That is, developers should simply add two blocks to the current stack (in no particular order) which should have equivalent behavior modulo typeful identity. Use of the 'eqv' prefix enables external tools to systematically discover, document, and validate these assertions. Further, they may later prove useful to optimizers and code rewriting.
~

@doc.assertEQ 
"a a -- a a; (annotation) assert equivalence 
 
     {&≡} :: (a*(a*e))→(a*(a*e))
       ^ that's U+2261 (dec 8801)
 
 This asserts that the two arguments should be equivalent. As an annotation, this has no observable impact on a valid program, but it may cause some invalid programs to be rejected at compile time or fail at run time.
 
 For blocks, the notion of equivalence is a little fuzzy because behavioral equivalence is undecidable in the general case. At the very least, an implementation must pass structurally equivalent blocks (i.e. same underlying ABC code).
~
@assertEQ pw %rr {&≡} %ll wx

@doc.assertEQ1 "as `assertEQ`, then drop the top copy (common)"
@assertEQ1 assertEQ drop

@doc.assertEQ1d "x y x -- x y; assert top x equivalent to bottom x"
@assertEQ1d   swapd assertEQ1 swap
@assertEQ1dd  rotd  assertEQ1 unrot
@assertEQ1ddd rolld assertEQ1 unroll

@doc.asynch
"Awelon's design includes a 'causal commutativity' property, which is enforced by all Awelon effects models. Causal commutativity allows an arbitrary amount of parallelism, constrained only by dependencies between values. An AO or ABC implementation is free to infer or assume useful places for parallelism (e.g. loading or saving files, or compiling a block), but developers may also suggest parallelism through annotations. 
 
 `{&asynch}` is such an annotation: it marks that a block should compute asynchronously when subsequently applied. Semantically, `asynch` is an identity function for blocks. But it may potentially impact performance:
 
     {&asynch} :: block→block
     asynch    :: block -- block (on AO stack)
 
 Note that `asynch` cannot model long-running behavior. Besides annotations being non-semantic and discretionary, Awelon requires and assumes termination for every subprogram. An unbounded loop is considered a bug. It would not be atypical for an Awelon runtime to wait for pending asynchronous operations to complete at certain stages - e.g. between REPL commands, or between paragraphs in a command stream. (Long-running behavior is modeled by other means, such as RDP or unbounded command streams.)
~ 
@asynch %r [{&asynch}] %r$l

@doc.compile
"The `{&compile}` annotation can support explicit, dynamic compilation. It operates on a block of bytecode and transparently returns a compiled version of that block, with intention to improve performance. This is potentially very useful for staged metaprogramming and other contexts where we might compose a hundred small blocks at runtime. Of course, any benefits must be weighed against the overhead for compiling and linking the code.
 
         {&compile} :: block→block 
         compile    :: [a→b] -- [a→b] (on AO stack)
 
 Static compilation is also useful, of course. Dynamic compilation can translate to static compilation via partial evaluation, or static per-word compilation may be available; see `doc.prefix.compile!` for more.
~
@compile %r [{&compile}] %r$l

@doc.prefix.compile!
"If you define word `compile!foo` this can act as a directive that the AO system should separately compile the word `foo`. The definition of `compile!foo` should be left empty, at least for now. The `compile!` word may later provide opportunity for optimization directives.
 
 This directive leverages ABC's separate compilation and linking model. An ABC subprogram may be saved and given a unique identifier. ABC uses its effects system to load and logically inline the subprogram - e.g. `{#resourceId}`. The `compile!foo` directive tells an AO compiler to replace the word with the equivalent resource identifier and save the bytecode at an appropriate location for linking. This doesn't require compilation, but provides an excellent opportunity for it. 
 
 The actual encoding of ABC resources is more sophisticated than plain bytecode, including compression and encryption steps. Relevant pseudocode:
 
         makeResource(bytecode):
             hashBC = secureHashBC(bytecode)
             cipherText = encrypt(hashBC,compress(bytecode))
             hashCT = secureHashCT(cipherText)
             store(hashCT,cipherText)
             resourceId = encode(append(hashCT,hashBC))
             return {#resourceId}
 
 The idea is that we should be able to distribute application resources through distrusted servers (cloud servers, content distribution networks, etc.), and also that we should be able to eliminate duplicates and maximize reuse via caching. There is a remaining vulnerability to 'confirmation' attacks, but developers can address this by indicating sensitive words with a `secret!foo` directive.
 
 See also: `doc.prefix.secret!` `doc.BinariesInABC`
~

@doc.prefix.secret!
"ABC's separate compilation and linking model uses [convergent encryption](http://en.wikipedia.org/wiki/Convergent_encryption), which is vulnerable to a class of 'confirmation' attacks, i.e. whereby an attacker might determine a ten digit bank account number by systematically encrypting all ten billion combinations and finding which is stored on the server. Confirmation attacks only work against low-entropy data, but a great deal of privacy-sensitive information is low entropy.
 
 To resist confirmation attacks, we can mix in a 'convergence secret', e.g. some high entropy text, with the ABC resource. If we add a 192-bit secret, the cost of a confirmation attack would increase by a factor of roughly 2^192. In ABC, a 192-bit convergence secret might be encoded as:
 
     "bpgzmjkydmfyfdhdhptzmnbpdjkndjnsgdjyzpxbsypshqfk
     ~%
 
 The prefix `secret!` acts as a directive word; `secret!foo` indicates that word `foo` should, when compiled to AO, be mixed with a convergence secret. The convergence secret should be deterministic, stable, and cryptographically secure. A simple HMAC of a secret together with the protected code would work well enough. The secrecy indicator may further support policies such as filtering or encrypting secret words when exporting a 'public' dictionary.
 
 AO programmers should indicate as secret any words directly containing privacy sensitive or intellectual property sensitive information. There is no need to mark words transitively. 
 
 See also: `doc.BinariesInABC`
~

@TODO.AO
"Much to do about AO
  * functions for association lists, maps, records, or similar
  *   maybe support for tables, too; relational algebra
  *     ideally a DSL supporting composition, optimization, compilation 
  * access to bytecodes
  * transpile ABC to JavaScript
  * functions for matrices and vector
  * look into FGL graph library (manipulating graphs with a zipper)
  * functions for sequences (finger-trees/ropes)
  * functions for parser combinators; grammar DSL
  *   should support derivative grammars & deep optimizations
  * AO bootstrap; optimizers and compilers for ABC, AO
  *   eventually do typechecking
  *   eventually get to AMBC
  * develop a colors/materials model? 
  *   named palette plus RGB? meh. 
  *   a DSL for mixing, lightening, and darkening colors?
  *   maybe a richer 'materials' model (cf. POV-ray) 
  *     with shine, roughness, transparency, etc.
  *     procedural texture generation, perlin noise
  *     automatic generation from images
  *     suitable for use in games...
  * functions for text, utf-8, binary, base64
  *   implement as stream transformers?
  * functions for kd-trees, geometries, scene-graphs
  * functions for textures, jpegs, gifs, compression and decompression
  * contraint models for staged dependency/policy/typeclass injection 
  * project euler? rosetta code? a simple tetris/breakout game?
  *   need a lot more performance, first!
  * simplified app type for quick integration with Haskell? (use plugins?)
  * 2D-3D scene-graphs based on enneatrees and zippers
  * secure pseduo-random number generators; probabilistic programs
  * math libs - linear algebra, symbolic maths
  * knowledge database or encyclopaedia?
  *   unicode
  *   world data? (countries, flags, populations, maps)
 
 AO's design philosophy is actually similar to Wolfram's - that code should have easy access to vast quantities of useful, maintainable data. AO provides this access in the form of words in a very large dictionary.
~


@doc.Zippers
"The zipper data structure was described by Gérard Huet in 1997. It enables navigation and modification of tree-structured data in a purely functional context. At any time, the original tree structure can be recovered with the modifications. For Awelon project, zippers are widely useful for modeling navigation through scene graphs or documents, and document-like structures. They may also be used for raycasting and rendering.
 
 To support user intuitions, zippers should be specialized for common data structures. However, AO does provide a few standard primitives for zippers on AO's product data type.
~

@doc.HigherOrderZippers
"Zippers are a first derivative on a data structure. However, higher derivatives are also very useful. For example, first derivative can focus on a single character in text, but second derivative models an expandable selection of text. In a scene graph, such could model a mobile bounding volume. 
 
 I don't grasp third derivatives yet, but my intuition is that it can help structurally abstract sweeps or convolutions, e.g. the process of casting a ray through a scene-graph.
~ 

@OLD_AO_ZIPPERS

"text below encoded in an earlier version of AO... which had comments, even
 % 
 % In Awelon, zipper operations apply to top object on current stack. 
 %
 %    zwrap - prepare zipper; stack object is initial target
 %    zf - if target was (x*y), x is now target; undo with zuf
 %    zs - if target was (x*y), y is now target; undo with zus
 %    zu - undoes last zipper navigation (selects zuf or zus)
 %    zunwrap - fully exit and unwrap zipper, even if deep
 %    zunwrap_ - just unwrap zipper
 %
 % Knowing the representation of the zipper structure isn't essential,
 % but it might be interesting to some people. 
 %
 %    zwrap :: x <~> x*(1*1) :: zunwrap_ (on stack)
 %    zf    :: (x*y)*(l*r) <~> x*(1*(y*(l*r))) :: zuf
 %    zs    :: (x*y)*(l*r) <~> y*((x*l)*r)     :: zus
 %
 % The 'zu' and 'zunwrap' operations must perform introspection. 
 %
 % To manipulate the zipper target, developers will usually use an
 % operation such as:
 %   
 %    zswap - switch target of zipper (2nd) with object on stack (1st)
 %    zpop  - move target to top of stack (unit placeholder)
 %    zpush - undo zpop
 %
 zwrap = intro1 intro1 assocl rot2 pzip assocl  
 zunwrap_ = assocr pzip rot2 assocr elim1 elim1  
 zf = assocr x intro1 assocl roll2 assocl 
 zuf = assocr roll2 assocr elim1 p assocl
 zs = assocr x roll3 pw roll2 assocl
 zus = assocr roll2 x roll3 pw assocl
 zswap = p assocr roll2 assocl x
 zpop = intro1S zswap
 zpush = zswap elim1S
 % TODO: zu, zu*
 zu = % look at wrapper to decide step back
 zu* = % iterative zu
 zunwrap = zu* zunwrap_
~

@doc.ValueSealing
"AO allows seal/unseal actions to be hard-coded using inline ABC. These are represented as:
 
     {:foo}       seal value with sealer 'foo'
     {.foo}       unseal value from sealer 'foo'
 
 The token 'foo' may be replaced by any arbitrary text. A sealed value cannot be observed or manipulated without first unsealing it with the same token. Of course, hard-coded tokens are not secure. (Secure value sealing involves construction of unique sealer/unsealer pairs.) To avoid even the illusion of security, and to simplify debugging, hard-coded sealers should favor simple, self-documenting tokens.
 
 Despite being insecure, hard-coded sealers are useful. They simplify reasoning and search for which code can access a value. They help document that some intermediate structures from an API are intended to be private or opaque. Introducing a new token for a test can help developers enforce parametricity. Value sealing can guard against accidental bindings, similar to 'newtype' in some other languages.
~
@sealer [{:}]
@unsealer [{.}]
@seal %r sealer %r$l
@unseal %r unsealer %r$l

@doc.ConcurrencyInAO
"AO has a natural capacity for parallelism (see @doc.CausalCommutativity). Concurrency is related, but is a different concept from parallelism. With concurrency, we have independently specified subprograms interacting in a shared environment. 
 
 To model concurrent behavior, AO developers need only to model the shared environment and interaction - e.g. to model message queues, registrations, and so on. This sort of explicit concurrency is explored with the incremental processes model (abstractly, `µP.[a→(P*b)]`). Implicit concurrency is also feasible, but only for an effects model that respects causal commutativity and spatial idempotence, such as Reactive Demand Programming (RDP).
 
 Parallel or concurrent behavior in AO tends to be fully deterministic. Non-determinism is possible, but must be expressed explicitly. Implicit non-determinism is incompatible with spatial idempotence (see @doc.SpatialIdempotence). An [oracle machine](http://en.wikipedia.org/wiki/Oracle_machine) could feasibly observe race-conditions, i.e. modeling each race as a unique, stateful resource.
~

@doc.SpatialIdempotence
"Spatial idempotence is an assumption in AO: if a subprogram is computed many times, it must each time return the same result and have no additional side-effects beyond computing it once. This assumption can be enforced through the effects model. However, it is often enforced by affine types to simply prevent expressing of an effect more than once. 
~

@doc.CausalCommutativity
"AO assumes causal commutativity. Any two subprograms can commute if they don't have a data-dependency relationship (i.e. where the output of one subprogram computes an input to another). This assumption is naturally enforced by the ABC primitives, but must additionally be enforced by whatever effectful capabilities are granted to the AO program.
 
 Causal commutativity is a valuable basis for many optimizations, and also for parallelism. Independent subprograms can be computed in parallel. Synchronization becomes implicit when results from parallel subprograms are used together for a side-effect.
~

@doc.CompositionIsFirstPrinciple
"Every compositional model consists of a trinity: components, operators, and properties. Compositional operators are algebraically closed; they combine two components into a third component. Compositional properties are invariant or inductive over the operators, i.e. `P(x*y)=F(P(x),'*',P(y))`. Thus, we can reason about properties of the composite based on the properties of the components. A set of components may be domain specific (such as diagrams, documents, sounds, and scene-graphs) or more general purpose (such as functions, arrows, matrices, grammars).
 
 Effective use of composition often requires domain-specific tradeoffs between the three aspects. For example, by limiting what we talk about (just diagrams) we can achieve more useful properties (e.g. bounding areas, efficient occlusion) and more operators (add, scale, rotate, translate, etc.). It is possible to switch between compositional models primarily by layering them, such that the output of one compositional model is translated to a component in another compositional model. 
 
 Composition is useful as a foundation for scalability and modularity. Compositional properties enable developers to reason about components without deep knowledge of the implementation details. Composition operators are also convenient due to their uniformity, i.e. we aren't forced to develop or learn a new ad-hoc language or interface for every object. The uniformity and compositional properties can lead to useful intuitions.
 
 Many models favored in conventional languages practice - including state machines, records, process loops, nominative types, conventional conditional expressions, even parametric abstraction - are not compositional. Fortunately, compositional alternatives are available. Grammars can operate as state machines (via parsing). Datalog or relations can generalize records. Processes can be compositional if we instead model them as partial and incremental (i.e. small-step processes; `µP.a→(P*b)`). Nominative types can be replaced with structural types. If/then/else and ad-hoc pattern-case conditional expressions can be replaced with a structural sum types. Ad-hoc parametric abstraction can often be replaced with staging and a reader monad.
 
 Awelon project strongly favors compositional models and designs. This should be reflected in AO's dictionaries and ontologies. I ask that all AO developers embrace composition as first design principle, pervasively, with priority over most other features.
 
 AO is designed to serve as a relatively generic compositional layer, to enable integration or translation of domain-specific models. AO's words are themselves software components. AO's compositional properties - especially causal commutativity, spatial idempotence, substructural types, and capability security - are very useful in this role. AO is also designed to mitigate common weaknesses of deeply layered abstractions by aggressive use of partial evaluation, dependent type analysis, and program search.
~

